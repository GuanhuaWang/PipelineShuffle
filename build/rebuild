#!/bin/bash

if [[ ! -d sbin ]]; then
    echo cannot find sbin, exit
    exit 1
fi

#build/mvn -Dhadoop.version=1.0.4 -Phadoop-1 -DskipTests clean package
build/mvn -Pyarn -Phadoop-2.4 -Dhadoop.version=2.4.0 -DskipTests clean package

cp -n ../spark-original/conf/* conf
grep scheduler conf/spark-defaults.conf || \
    sed -i -e '1ispark.scheduler.pipe true\' conf/spark-defaults.conf

rm logs/*

sbin/stop-all.sh
# rsync everytime you change spark.scheduler.pipe true/false
# there is no need for conf on spark.slaves.number which should be used for counting slave number.
/root/spark-ec2/copy-dir  ~/root/spark
sbin/start-all.sh
